
<html>

<head>
<title>DeepLidar</title></head>

<body>

<div class=WordSection1>

<p class=MsoNormal><o:p>&nbsp;</o:p></p>

<div align=center>

<table class=MsoNormalTable border=0 cellpadding=0 width=800 style='width:600.0pt;
 mso-cellspacing:1.5pt;mso-yfti-tbllook:1184;mso-padding-alt:0cm 5.4pt 0cm 5.4pt'>
 
 <tr>
  <td>
  <p align=center style='text-align:center'>
  <b style='mso-bidi-font-weight:normal'>
  <span style='font-size:24.0pt'>DeepLiDAR: Deep Surface Normal Guided Depth Prediction for Outdoor Scene
from Sparse LiDAR Data and Single Color Image</span></b></p>
  </td>
 </tr>
</table>

</div>

<p class=MsoNormal><o:p>&nbsp;</o:p></p>

<div align=center>

<table class=MsoNormalTable border=0 cellpadding=0 width=800 style='width:600.0pt;
 mso-cellspacing:1.5pt;mso-yfti-tbllook:1184;mso-padding-alt:0cm 5.4pt 0cm 5.4pt'
 id=Table2>
 
  <tr style='mso-yfti-irow:0;mso-yfti-firstrow:yes;mso-yfti-lastrow:yes'>
  <td ></td>
 </tr>
</table>

</div>

<p></p>

<div align=center>

<table class=MsoNormalTable border=0 cellpadding=0 width=800 style='width:600.0pt;
 mso-cellspacing:1.5pt;mso-yfti-tbllook:1184;mso-padding-alt:0cm 5.4pt 0cm 5.4pt'>
 
 <tr style='mso-fareast-font-family:"Times New Roman"' style='font-size:14.0pt'>
  <td width=803>
  <h3>Abstract:</h3>
  
  <p style="text-align: justify">In this paper, we propose a deep learning architecture
that produces accurate dense depth for the outdoor scene
from a single color image and a sparse depth. Inspired
by the indoor depth completion, our network estimates sur-
face normals as the intermediate representation to produce
dense depth, and can be trained end-to-end. With a modified
encoder-decoder structure, our network effectively fuses the
dense color image and the sparse LiDAR depth. To address
outdoor specific challenges, our network predicts a confi-
dence mask to handle mixed LiDAR signals near foreground
boundaries due to occlusion, and combines estimates from
the color image and surface normals with learned atten-
tion maps to improve the depth accuracy especially for dis-
tant areas. Extensive experiments demonstrate that our
model improves upon the state-of-the-art performance on
KITTI depth completion benchmark. Ablation study shows
the positive impact of each model components to the final
performance, and comprehensive analysis shows that our
model generalizes well to the input with higher sparsity or
from indoor scenes.</p>
   
  <span><img width="1702" height="443" alt="image" src="JiaxiongQ.github.io/projects/CVPR_2019_dl/Image_pipline.png"/></span>
  </div>
  <h3><strong>Download:</strong>
  </h3>
  
  <p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Qiu_DeepLiDAR_Deep_Surface_Normal_Guided_Depth_Prediction_for_Outdoor_Scene_CVPR_2019_paper.pdf">"DeepLiDAR: Deep Surface Normal Guided Depth Prediction for Outdoor Scene from Sparse LiDAR Data and Single Color Image"</a> <br>
   Jiaxiong Qiu*, Zhaopeng Cui*, Yinda Zhang*, Xingdi Zhang, Shuaicheng Liu, Bing Zeng, and Marc Pollefeys(*equal contribution)<br>
    Computer Vision and Pattern Recognition (CVPR 2019).</p>
  <p><a href="https://github.com/JiaxiongQ/Need2Adjust" title="DeepLiDAR_code">Code</a></p>
  <p>&nbsp;</p></td>
 </tr>
</table>

</div>

</div>

</body>

</html>

